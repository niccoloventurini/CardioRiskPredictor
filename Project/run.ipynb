{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\nicco\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\_iotools.py:672\u001b[0m, in \u001b[0;36mStringConverter._loose_call\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 672\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(value)\n\u001b[0;32m    673\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: ''",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nicco\\OneDrive\\Desktop\\Applicazioni\\Neuro-X\\ML\\project 1\\ml-project-1-min\\project1\\run.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nicco/OneDrive/Desktop/Applicazioni/Neuro-X/ML/project%201/ml-project-1-min/project1/run.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m x_train_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(base_path, \u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mx_train.csv\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m#load the path of x_train\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nicco/OneDrive/Desktop/Applicazioni/Neuro-X/ML/project%201/ml-project-1-min/project1/run.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m y_train_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(base_path, \u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39my_train.csv\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m#load the path of y_train\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nicco/OneDrive/Desktop/Applicazioni/Neuro-X/ML/project%201/ml-project-1-min/project1/run.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m y,x,ind \u001b[39m=\u001b[39m load_data(x_train_path,y_train_path) \u001b[39m#load x_train and y _train\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicco/OneDrive/Desktop/Applicazioni/Neuro-X/ML/project%201/ml-project-1-min/project1/run.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m#sub_sample true to test only first 5000 people\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicco/OneDrive/Desktop/Applicazioni/Neuro-X/ML/project%201/ml-project-1-min/project1/run.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m x_test_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(base_path, \u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mx_test.csv\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m#load the path of x_test\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nicco\\OneDrive\\Desktop\\Applicazioni\\Neuro-X\\ML\\project 1\\ml-project-1-min\\project1\\data_preprocessing.py:22\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(data_path_x, data_path_y, sub_sample)\u001b[0m\n\u001b[0;32m     20\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mgenfromtxt(data_path_y, delimiter\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m, skip_header\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m)\n\u001b[0;32m     21\u001b[0m y \u001b[39m=\u001b[39m y[:,\u001b[39m1\u001b[39m] \u001b[39m#eliminate the index of the matrix\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mgenfromtxt(data_path_x, delimiter\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m\"\u001b[39;49m, skip_header\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, missing_values\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mnan)\u001b[39m#max rows load only the first 50 coloumns\u001b[39;00m\n\u001b[0;32m     23\u001b[0m ids \u001b[39m=\u001b[39m x[:, \u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m) \u001b[39m#index of the matrix\u001b[39;00m\n\u001b[0;32m     24\u001b[0m input_data \u001b[39m=\u001b[39m x[:, \u001b[39m2\u001b[39m:]\n",
      "File \u001b[1;32mc:\\Users\\nicco\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\npyio.py:2281\u001b[0m, in \u001b[0;36mgenfromtxt\u001b[1;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, ndmin, like)\u001b[0m\n\u001b[0;32m   2277\u001b[0m \u001b[39m# Convert each value according to the converter:\u001b[39;00m\n\u001b[0;32m   2278\u001b[0m \u001b[39m# We want to modify the list in place to avoid creating a new one...\u001b[39;00m\n\u001b[0;32m   2279\u001b[0m \u001b[39mif\u001b[39;00m loose:\n\u001b[0;32m   2280\u001b[0m     rows \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[1;32m-> 2281\u001b[0m         \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m[[conv\u001b[39m.\u001b[39m_loose_call(_r) \u001b[39mfor\u001b[39;00m _r \u001b[39min\u001b[39;00m \u001b[39mmap\u001b[39m(itemgetter(i), rows)]\n\u001b[0;32m   2282\u001b[0m               \u001b[39mfor\u001b[39;00m (i, conv) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(converters)]))\n\u001b[0;32m   2283\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2284\u001b[0m     rows \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[0;32m   2285\u001b[0m         \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m[[conv\u001b[39m.\u001b[39m_strict_call(_r) \u001b[39mfor\u001b[39;00m _r \u001b[39min\u001b[39;00m \u001b[39mmap\u001b[39m(itemgetter(i), rows)]\n\u001b[0;32m   2286\u001b[0m               \u001b[39mfor\u001b[39;00m (i, conv) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(converters)]))\n",
      "File \u001b[1;32mc:\\Users\\nicco\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\npyio.py:2281\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2277\u001b[0m \u001b[39m# Convert each value according to the converter:\u001b[39;00m\n\u001b[0;32m   2278\u001b[0m \u001b[39m# We want to modify the list in place to avoid creating a new one...\u001b[39;00m\n\u001b[0;32m   2279\u001b[0m \u001b[39mif\u001b[39;00m loose:\n\u001b[0;32m   2280\u001b[0m     rows \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[1;32m-> 2281\u001b[0m         \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m[[conv\u001b[39m.\u001b[39m_loose_call(_r) \u001b[39mfor\u001b[39;00m _r \u001b[39min\u001b[39;00m \u001b[39mmap\u001b[39m(itemgetter(i), rows)]\n\u001b[0;32m   2282\u001b[0m               \u001b[39mfor\u001b[39;00m (i, conv) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(converters)]))\n\u001b[0;32m   2283\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2284\u001b[0m     rows \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[0;32m   2285\u001b[0m         \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m[[conv\u001b[39m.\u001b[39m_strict_call(_r) \u001b[39mfor\u001b[39;00m _r \u001b[39min\u001b[39;00m \u001b[39mmap\u001b[39m(itemgetter(i), rows)]\n\u001b[0;32m   2286\u001b[0m               \u001b[39mfor\u001b[39;00m (i, conv) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(converters)]))\n",
      "File \u001b[1;32mc:\\Users\\nicco\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\npyio.py:2281\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2277\u001b[0m \u001b[39m# Convert each value according to the converter:\u001b[39;00m\n\u001b[0;32m   2278\u001b[0m \u001b[39m# We want to modify the list in place to avoid creating a new one...\u001b[39;00m\n\u001b[0;32m   2279\u001b[0m \u001b[39mif\u001b[39;00m loose:\n\u001b[0;32m   2280\u001b[0m     rows \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[1;32m-> 2281\u001b[0m         \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m[[conv\u001b[39m.\u001b[39;49m_loose_call(_r) \u001b[39mfor\u001b[39;00m _r \u001b[39min\u001b[39;00m \u001b[39mmap\u001b[39m(itemgetter(i), rows)]\n\u001b[0;32m   2282\u001b[0m               \u001b[39mfor\u001b[39;00m (i, conv) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(converters)]))\n\u001b[0;32m   2283\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2284\u001b[0m     rows \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[0;32m   2285\u001b[0m         \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m[[conv\u001b[39m.\u001b[39m_strict_call(_r) \u001b[39mfor\u001b[39;00m _r \u001b[39min\u001b[39;00m \u001b[39mmap\u001b[39m(itemgetter(i), rows)]\n\u001b[0;32m   2286\u001b[0m               \u001b[39mfor\u001b[39;00m (i, conv) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(converters)]))\n",
      "File \u001b[1;32mc:\\Users\\nicco\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\_iotools.py:673\u001b[0m, in \u001b[0;36mStringConverter._loose_call\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    672\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc(value)\n\u001b[1;32m--> 673\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;49;00m:\n\u001b[0;32m    674\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from data_preprocessing import *\n",
    "from implementations import *\n",
    "from validations import *\n",
    "from helpers import *\n",
    "from evaluation import *\n",
    "\n",
    "base_path = os.path.dirname('data')\n",
    "x_train_path = os.path.join(base_path, 'data', 'x_train.csv') #load the path of x_train\n",
    "y_train_path = os.path.join(base_path, 'data', 'y_train.csv') #load the path of y_train\n",
    "y,x,ind = load_data(x_train_path,y_train_path) #load x_train and y _train\n",
    "#sub_sample true to test only first 5000 people\n",
    "\n",
    "x_test_path = os.path.join(base_path, 'data', 'x_test.csv') #load the path of x_test\n",
    "x_test, ids_test = load_test_data(x_test_path) #load x test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 320)\n",
      "(109379, 320)\n"
     ]
    }
   ],
   "source": [
    "# default values of gamma, lambda, degree and loss bias\n",
    "gamma_ = 0.8\n",
    "# lambda_ = 0.01 #uncomment to use lambda\n",
    "degree = 2\n",
    "loss_bias= 0.01\n",
    "\n",
    "# search space for hyper-parameters\n",
    "#create vector to find the best values of gamma, lambda, degree and loss biasgamma, lambda, degree and loss bias\n",
    "degrees = [1, 2, 3]\n",
    "\n",
    "#uncomment to use lambda\n",
    "# lambdas = [\n",
    "#     0.5,\n",
    "#     0.1,\n",
    "#     0.01,\n",
    "#     0.001\n",
    "# ]\n",
    "\n",
    "gammas = [\n",
    "    0.5,\n",
    "    0.6,\n",
    "    0.7,\n",
    "    0.8,\n",
    "    0.9,\n",
    "]\n",
    "\n",
    "loss_biases = [\n",
    "    0.001,\n",
    "    0.01,\n",
    "    0.1\n",
    "]\n",
    "\n",
    "#set k_fold, max iteration and create a seed\n",
    "k_fold = 5\n",
    "seed = 381\n",
    "max_iters = 5000\n",
    "print(np.shape(x))\n",
    "print(np.shape(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = False #set it True to do the cross-validation\n",
    "\n",
    "if validation:\n",
    "    cross_deg,f1_deg = cross_val_degree(degrees, k_fold, seed, x, y, gamma_, max_iters, loss_bias)\n",
    "\n",
    "    print(cross_deg)\n",
    "    print(f1_deg)\n",
    "    #uncomment to do the cross-validation of the lambda\n",
    "    # cross_deg = 2\n",
    "    # cross_gamma = 0.8\n",
    "    # cross_loss_bias= 0.01\n",
    "\n",
    "    #uncomment to do the cross-validation of lambda\n",
    "    # cross_lambda,f1_lamda = cross_val_lambda(lambdas, k_fold, seed, x, y, cross_deg, cross_gamma, max_iters, cross_loss_bias)\n",
    "\n",
    "    # print(cross_lambda)\n",
    "    # print(f1_lamda)\n",
    "\n",
    "    cross_gamma,f1_gamma = cross_val_gamma_(gammas, k_fold, seed, x, y, cross_deg, max_iters, loss_bias)\n",
    "\n",
    "    print(cross_gamma)\n",
    "    print(f1_gamma)\n",
    "\n",
    "    cross_loss_bias,f1_bias = cross_val_loss_bias(loss_biases, k_fold, seed, x, y, cross_deg, cross_gamma, max_iters)\n",
    "\n",
    "    print(cross_loss_bias)\n",
    "    print(f1_bias) \n",
    "else:\n",
    "    #obtain the default values\n",
    "    # cross_lambda = lambda_ #uncomment when the lambda is present\n",
    "    cross_gamma = gamma_\n",
    "    cross_deg = degree\n",
    "    cross_loss_bias = loss_bias\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the cross validation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0.8\n",
      "0.01\n"
     ]
    }
   ],
   "source": [
    "print(cross_deg)\n",
    "# print(cross_lambda) #uncomment when the lambda is present\n",
    "print(cross_gamma)\n",
    "print(cross_loss_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before poly (328135, 270)\n",
      "shape after poly (328135, 541)\n",
      "no of 0 299160\n",
      "no of 1 28975\n",
      "(473010, 541)\n",
      "(473010,)\n",
      "[1. 1. 1. ... 0. 1. 0.]\n",
      "(473010, 541)\n"
     ]
    }
   ],
   "source": [
    "#preprocess the data\n",
    "x_preproc, x_test_preproc,y_preproc = preprocess(x, cross_deg, True, True, True, x_test=x_test, y = y,repetition=6)\n",
    "print(np.shape(x_preproc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce size of the x_train and y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 541)\n",
      "(100000,)\n",
      "(109379, 541)\n"
     ]
    }
   ],
   "source": [
    "#reduce the size of the matrix to do the logistic regression\n",
    "x_preproc_train = x_preproc[0:100000,:]\n",
    "y_preproc_train = y_preproc[0:100000]\n",
    "\n",
    "print(np.shape(x_preproc_train))\n",
    "print(np.shape(y_preproc_train))\n",
    "print(np.shape(x_test_preproc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6931471805599436\n",
      "100 0.5169657300431745\n",
      "200 0.4961707196268774\n",
      "300 0.47574477205049304\n",
      "400 0.46898124056692725\n",
      "500 0.46977040271981274\n",
      "600 0.47351550776061985\n",
      "700 0.462258585140022\n",
      "800 0.462352218937216\n",
      "900 0.464027728614034\n",
      "1000 0.4544023633056885\n",
      "1100 0.45750589945272435\n",
      "1200 0.45887478553245126\n",
      "1300 0.45695913773893887\n",
      "1400 0.4543394918970676\n",
      "1500 0.45816404327775456\n",
      "1600 0.46174559569787293\n",
      "1700 0.456069010111096\n",
      "1800 0.46577772892618285\n",
      "1900 0.45515932770845896\n",
      "2000 0.4541808689209911\n",
      "2100 0.46319213091931083\n",
      "2200 0.45231710430546185\n",
      "2300 0.45514048039946176\n",
      "2400 0.4575297298665872\n",
      "2500 0.4498926979737815\n",
      "2600 0.4545715805188148\n",
      "2700 0.4520351928441213\n",
      "2800 0.4518630130077457\n",
      "2900 0.45954788717799366\n",
      "3000 0.4583120972083178\n",
      "3100 0.44974017431647534\n",
      "3200 0.4498697987768877\n",
      "3300 0.46161266631821635\n",
      "3400 0.4606516632840727\n",
      "3500 0.4486197174062137\n",
      "3600 0.4505910455443533\n",
      "3700 0.44910277302253215\n",
      "3800 0.4586416387893244\n",
      "3900 0.45812059317964804\n",
      "4000 0.46024718470363235\n",
      "4100 0.45081652111768045\n",
      "4200 0.4573847553448151\n",
      "4300 0.4486182961331445\n",
      "4400 0.46008860891545866\n",
      "4500 0.45561225805702354\n",
      "4600 0.4500660963436803\n",
      "4700 0.4481389803500669\n",
      "4800 0.457293117205472\n",
      "4900 0.45821876076075624\n"
     ]
    }
   ],
   "source": [
    "N,D= get_dim(x_test_preproc) #get the dimension of x_test_preproc\n",
    "w0= np.zeros(D) #get a vector of shape D, the number of the columns of x_test_preproc\n",
    "\n",
    "max_iters = 5000 #number of iteration of logistic regression\n",
    "\n",
    "w,loss = logistic_regression(y_preproc_train, x_preproc_train, w0, max_iters, cross_gamma,cross_loss_bias) #Logistic regression\n",
    "# w,loss = reg_logistic_regression_lasso(y_preproc_train, x_preproc_train, cross_lambda, w0, max_iters, cross_gamma, cross_loss_bias) #uncomment this function to do the regularized logistic regression with Lasso "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3931411  0.00679339 0.20048128 ... 0.13262211 0.82095147 0.24946657]\n",
      "[-1. -1. -1. ... -1.  1. -1.]\n"
     ]
    }
   ],
   "source": [
    "y_hat= logistic_prediction(x_test_preproc,w) #logistic prediction\n",
    "print(y_hat)\n",
    "y_predictions = zero_to_minone(y_hat) #change from 0 to -1\n",
    "\n",
    "print(y_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(ids_test,y_predictions, \"submission_exp3E.csv\") #create submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See f1 score of prediction on some train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  78.318 %\n",
      "Percentage of correct -1: 84.60419368101458\n",
      "Percentage of correct 1: 67.50448833034112\n",
      "F1 score: 0.6959643267801554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6959643267801554"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the model on the last 50.000 subject of the train dataset\n",
    "try_test = x_preproc[-50000:,:]\n",
    "try_y_preproc = y_preproc[-50000:]\n",
    "\n",
    "try_y_hat = logistic_prediction(try_test,w)\n",
    "\n",
    "try_y_predictions = zero_to_minone(try_y_hat)\n",
    "\n",
    "f1_score(try_y_preproc,try_y_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
